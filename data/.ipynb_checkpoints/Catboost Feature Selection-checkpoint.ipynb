{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OrdinalEncoder as oe\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('training_set_labels.csv').drop('respondent_id', axis = 1)\n",
    "\n",
    "X = pd.read_csv('training_set_features.csv').drop('respondent_id', axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<= $75,000, Above Poverty    12777\n",
       "> $75,000                     6810\n",
       "Below Poverty                 2697\n",
       "Name: income_poverty, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['income_poverty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals = []\n",
    "non_numericals = []\n",
    "\n",
    "for column in X_train.columns:\n",
    "    if X_train[column].dtype == 'float64':\n",
    "        numericals.append(column)\n",
    "    if X_train[column].dtype == 'object':\n",
    "        non_numericals.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age_group',\n",
       " 'education',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'income_poverty',\n",
       " 'marital_status',\n",
       " 'rent_or_own',\n",
       " 'employment_status',\n",
       " 'hhs_geo_region',\n",
       " 'census_msa',\n",
       " 'employment_industry',\n",
       " 'employment_occupation']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline([('imputer', SimpleImputer(strategy='constant',fill_value= 0, add_indicator = True)),\n",
    "                               ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline([('cat_imputer', SimpleImputer(strategy='most_frequent', add_indicator = True)),\n",
    "                                    ('encoder', OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numericals),\n",
    "            (\"cat\", categorical_transformer, non_numericals),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['race', 'sex', \n",
    "       'marital_status', 'rent_or_own',  'hhs_geo_region',\n",
    "       'census_msa', 'employment_industry', 'employment_occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features_indices = np.where(X_train.dtypes != float)[0]\n",
    "categorical_features_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(X_train, X_test, y_train, y_test,\n",
    "                         baseline_models, \n",
    "                         preprocessor,\n",
    "                         folder_name = None, \n",
    "                         ):\n",
    "    \n",
    "    # Create a summary dictionary\n",
    "    summary_dict = {}\n",
    "    \n",
    "    for name, model in baseline_models.items():\n",
    "        \n",
    "        # transform the features    \n",
    "        processor = model['preprocessor']\n",
    "        X_train_processed = processor.fit_transform(X_train)\n",
    "        X_test_processed = processor.transform(X_test)\n",
    "    \n",
    "        # Cross validation\n",
    "        model['train_accuracy_score'] = np.mean(cross_val_score(model['regressor'], \n",
    "                                                        X_train_processed, y_train.values.ravel(), \n",
    "                                                        scoring=\"accuracy\", cv=5))\n",
    "    \n",
    "        train_accuracy_score = model['train_accuracy_score']\n",
    "    \n",
    "        # fit the new model and make predictions\n",
    "        new_model = model['regressor']\n",
    "        new_model.fit(X_train_processed, y_train.values.ravel())\n",
    "        preds = new_model.predict(X_test_processed)\n",
    "        y_score = new_model.predict_proba(X_test_processed)\n",
    "\n",
    "        # get our scoring metrics\n",
    "        model['test_accuracy_score'] = accuracy_score(y_test, preds)\n",
    "        test_accuracy_score = model['test_accuracy_score']\n",
    "        \n",
    "        model['auc_score'] = roc_auc_score(y_test, y_score[:,1])\n",
    "        auc_score = model['auc_score']\n",
    "        \n",
    "        model['recall_score'] = recall_score(y_test, preds)\n",
    "        model['precision_score'] = f1_score(y_test, preds)\n",
    "        model['f1_score'] = precision_score(y_test, preds)\n",
    "        \n",
    "        recall = recall_score(y_test, preds)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        precision = precision_score(y_test, preds)\n",
    "        \n",
    "        # Visualisations\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_score[:,1])\n",
    "        model['fpr'] = fpr\n",
    "        model['tpr'] = tpr\n",
    "        model['thresholds'] = thresholds\n",
    "    \n",
    "        # Saving the model\n",
    "        if folder_name == None:\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(f'models/{name}/{folder_name}') \n",
    "            filepath = f'models/{name}/{folder_name}/baseline_model.pickl'\n",
    "            pickle.dump(new_model, open(filepath, 'wb'))\n",
    "        \n",
    "        #Place everything into a dictionary and place that into the summary list\n",
    "        summary_dict.update({name: {\n",
    "                                   'train_score': train_accuracy_score, 'test_score': test_accuracy_score,\n",
    "                                   'recall': recall, 'precision': precision, 'f1': f1,\n",
    "                                   'auc': auc_score, 'tpr': tpr, 'fpr': fpr\n",
    "                                   }})\n",
    "\n",
    "    return summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed_df = pd.DataFrame(data=X_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc = CatBoostClassifier(iterations=100,\n",
    "        learning_rate=0.1,\n",
    "        random_strength=10,\n",
    "        bagging_temperature=10,\n",
    "        max_bin=30,\n",
    "        grow_policy='Lossguide',\n",
    "        min_data_in_leaf=10,\n",
    "        od_type='Iter',\n",
    "        od_wait=100,\n",
    "        depth=10,\n",
    "        l2_leaf_reg=100,\n",
    "        one_hot_max_size=5,\n",
    "        custom_metric='AUC',\n",
    "        loss_function='Logloss',\n",
    "        auto_class_weights='Balanced',\n",
    "        verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25194    18 - 34 Years\n",
       "14006    45 - 54 Years\n",
       "11285    45 - 54 Years\n",
       "2900     55 - 64 Years\n",
       "19083    18 - 34 Years\n",
       "             ...      \n",
       "21575    55 - 64 Years\n",
       "5390     55 - 64 Years\n",
       "860      55 - 64 Years\n",
       "15795    35 - 44 Years\n",
       "23654    18 - 34 Years\n",
       "Name: age_group, Length: 20030, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['age_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2723a423130>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbc.fit(X_train_processed_df, y_train.h1n1_vaccine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc_pred = cbc.predict(X_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20030,)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbc_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7814026136402172"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train.h1n1_vaccine, cbc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6677, 2)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cbc.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7946682641905047"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.h1n1_vaccine, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744530698659139"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test.h1n1_vaccine, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.606147658718759"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test.h1n1_vaccine, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5111434108527132"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test.h1n1_vaccine, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2723a423130>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbc.fit(X_train_processed_df, y_train.seasonal_vaccine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6518529548214063"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train.seasonal_vaccine, cbc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6610753332334881"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test.seasonal_vaccine, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, cv\n",
    "train_dataset = Pool(X_train_processed,\n",
    "                     label=y_train.h1n1_vaccine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations':trial.suggest_categorical('iterations', [100,200,300,500,1000,1200,1500]),\n",
    "        'learning_rate':trial.suggest_float(\"learning_rate\", 0.001, 0.3),\n",
    "        'random_strength':trial.suggest_int(\"random_strength\", 1,10),\n",
    "        'bagging_temperature':trial.suggest_int(\"bagging_temperature\", 0,10),\n",
    "        'max_bin':trial.suggest_categorical('max_bin', [4,5,6,8,10,20,30]),\n",
    "        'grow_policy':trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'min_data_in_leaf':trial.suggest_int(\"min_data_in_leaf\", 1,10),\n",
    "        'od_type' : \"Iter\",\n",
    "        'od_wait' : 100,\n",
    "        \"depth\": trial.suggest_int(\"max_depth\", 2,10),\n",
    "        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
    "         'one_hot_max_size':trial.suggest_categorical('one_hot_max_size', [5,10,12,100,500,1024]),\n",
    "        'custom_metric' : ['AUC'],\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        'auto_class_weights':trial.suggest_categorical('auto_class_weights', ['Balanced', 'SqrtBalanced']),\n",
    "        }\n",
    "\n",
    "    scores = cv(train_dataset,\n",
    "            param,\n",
    "            fold_count=5, \n",
    "            early_stopping_rounds=10,         \n",
    "            plot=False, verbose=False)\n",
    "\n",
    "    return scores['test-AUC-mean'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:29:53,154]\u001b[0m A new study created in memory with name: no-name-602511eb-a740-4557-a582-d8c86d46ffb4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4169302285\n",
      "bestIteration = 554\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4320167812\n",
      "bestIteration = 554\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4320521886\n",
      "bestIteration = 620\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4137110671\n",
      "bestIteration = 512\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:30:11,395]\u001b[0m Trial 0 finished with value: 0.8646284729540925 and parameters: {'iterations': 1500, 'learning_rate': 0.029356482739949695, 'random_strength': 8, 'bagging_temperature': 10, 'max_bin': 6, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 1, 'max_depth': 4, 'l2_leaf_reg': 0.001991194871120998, 'one_hot_max_size': 100, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 0 with value: 0.8646284729540925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4404139222\n",
      "bestIteration = 531\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4122171118\n",
      "bestIteration = 153\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4295098882\n",
      "bestIteration = 148\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.431511785\n",
      "bestIteration = 140\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4122076105\n",
      "bestIteration = 155\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:30:15,338]\u001b[0m Trial 1 finished with value: 0.8651912924685078 and parameters: {'iterations': 200, 'learning_rate': 0.1464067066361795, 'random_strength': 10, 'bagging_temperature': 3, 'max_bin': 10, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'max_depth': 3, 'l2_leaf_reg': 0.028402775147703313, 'one_hot_max_size': 500, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4418847921\n",
      "bestIteration = 132\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4198312772\n",
      "bestIteration = 66\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4338020226\n",
      "bestIteration = 51\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4392519813\n",
      "bestIteration = 47\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.423011524\n",
      "bestIteration = 52\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:30:19,342]\u001b[0m Trial 2 finished with value: 0.8604684339560922 and parameters: {'iterations': 200, 'learning_rate': 0.27287829596201946, 'random_strength': 8, 'bagging_temperature': 8, 'max_bin': 10, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 1, 'max_depth': 5, 'l2_leaf_reg': 0.027330135035255495, 'one_hot_max_size': 10, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4450773829\n",
      "bestIteration = 54\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4178642463\n",
      "bestIteration = 474\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4347398981\n",
      "bestIteration = 424\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4337643232\n",
      "bestIteration = 540\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4153126011\n",
      "bestIteration = 382\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:30:27,869]\u001b[0m Trial 3 finished with value: 0.86340320707297 and parameters: {'iterations': 1200, 'learning_rate': 0.0603209284932487, 'random_strength': 3, 'bagging_temperature': 7, 'max_bin': 4, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 2, 'max_depth': 2, 'l2_leaf_reg': 1.300471404766049e-07, 'one_hot_max_size': 10, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4431121835\n",
      "bestIteration = 364\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.416787541\n",
      "bestIteration = 88\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4382255685\n",
      "bestIteration = 65\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4374459833\n",
      "bestIteration = 78\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4207838483\n",
      "bestIteration = 73\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:30:30,530]\u001b[0m Trial 4 finished with value: 0.8588732376008072 and parameters: {'iterations': 300, 'learning_rate': 0.22423670437233847, 'random_strength': 6, 'bagging_temperature': 2, 'max_bin': 30, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 4, 'max_depth': 4, 'l2_leaf_reg': 0.00010293033487726667, 'one_hot_max_size': 500, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.458253497\n",
      "bestIteration = 35\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4820225261\n",
      "bestIteration = 99\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4949513849\n",
      "bestIteration = 99\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4927225443\n",
      "bestIteration = 99\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4800932551\n",
      "bestIteration = 99\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:30:33,082]\u001b[0m Trial 5 finished with value: 0.8514272932659803 and parameters: {'iterations': 100, 'learning_rate': 0.06628011038512191, 'random_strength': 4, 'bagging_temperature': 4, 'max_bin': 20, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 3, 'max_depth': 2, 'l2_leaf_reg': 13.751833235431702, 'one_hot_max_size': 100, 'auto_class_weights': 'Balanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.5011670429\n",
      "bestIteration = 99\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4194642491\n",
      "bestIteration = 126\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4460610622\n",
      "bestIteration = 68\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4375303515\n",
      "bestIteration = 92\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4253720716\n",
      "bestIteration = 89\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:30:45,841]\u001b[0m Trial 6 finished with value: 0.8583759931549235 and parameters: {'iterations': 1200, 'learning_rate': 0.09658215406978513, 'random_strength': 8, 'bagging_temperature': 2, 'max_bin': 30, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 6, 'max_depth': 10, 'l2_leaf_reg': 2.6558249848041764, 'one_hot_max_size': 5, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4464435425\n",
      "bestIteration = 81\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4519628868\n",
      "bestIteration = 96\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4656011196\n",
      "bestIteration = 93\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4731202274\n",
      "bestIteration = 111\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4431378536\n",
      "bestIteration = 107\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:30:48,363]\u001b[0m Trial 7 finished with value: 0.863268734916975 and parameters: {'iterations': 500, 'learning_rate': 0.2714096381817127, 'random_strength': 4, 'bagging_temperature': 6, 'max_bin': 8, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'max_depth': 2, 'l2_leaf_reg': 4.9369231964322795, 'one_hot_max_size': 1024, 'auto_class_weights': 'Balanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4743531603\n",
      "bestIteration = 92\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4182557831\n",
      "bestIteration = 103\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4330939869\n",
      "bestIteration = 91\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4306942257\n",
      "bestIteration = 107\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4132711653\n",
      "bestIteration = 83\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:30:51,091]\u001b[0m Trial 8 finished with value: 0.8628349525838763 and parameters: {'iterations': 1500, 'learning_rate': 0.2053434310118264, 'random_strength': 8, 'bagging_temperature': 0, 'max_bin': 20, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 10, 'max_depth': 3, 'l2_leaf_reg': 9.501510078266123e-06, 'one_hot_max_size': 500, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4444497564\n",
      "bestIteration = 81\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4468518985\n",
      "bestIteration = 16\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4464740123\n",
      "bestIteration = 20\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4449233945\n",
      "bestIteration = 30\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4367403759\n",
      "bestIteration = 18\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:30:53,634]\u001b[0m Trial 9 finished with value: 0.849725480961643 and parameters: {'iterations': 100, 'learning_rate': 0.25900665720714294, 'random_strength': 3, 'bagging_temperature': 0, 'max_bin': 6, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 8, 'max_depth': 7, 'l2_leaf_reg': 1.1694576328936887e-07, 'one_hot_max_size': 12, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.460238864\n",
      "bestIteration = 40\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.463580193\n",
      "bestIteration = 82\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.491848518\n",
      "bestIteration = 64\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4904919368\n",
      "bestIteration = 41\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4731387746\n",
      "bestIteration = 74\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:30:58,198]\u001b[0m Trial 10 finished with value: 0.8501888132064981 and parameters: {'iterations': 200, 'learning_rate': 0.15034104921866256, 'random_strength': 10, 'bagging_temperature': 4, 'max_bin': 5, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 6, 'max_depth': 7, 'l2_leaf_reg': 0.06866979073979589, 'one_hot_max_size': 500, 'auto_class_weights': 'Balanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4895294901\n",
      "bestIteration = 54\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4210802771\n",
      "bestIteration = 1499\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4355994753\n",
      "bestIteration = 1499\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4354660049\n",
      "bestIteration = 1499\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4198432\n",
      "bestIteration = 1499\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:32:20,200]\u001b[0m Trial 11 finished with value: 0.8626007200419238 and parameters: {'iterations': 1500, 'learning_rate': 0.008172454094813715, 'random_strength': 10, 'bagging_temperature': 9, 'max_bin': 6, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 4, 'max_depth': 5, 'l2_leaf_reg': 0.004159650728547698, 'one_hot_max_size': 100, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4440428936\n",
      "bestIteration = 1499\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4152194359\n",
      "bestIteration = 101\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4344109053\n",
      "bestIteration = 89\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4334137952\n",
      "bestIteration = 99\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4189940948\n",
      "bestIteration = 107\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:32:23,739]\u001b[0m Trial 12 finished with value: 0.8625164587073423 and parameters: {'iterations': 1000, 'learning_rate': 0.15199867028113, 'random_strength': 7, 'bagging_temperature': 10, 'max_bin': 10, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 1, 'max_depth': 4, 'l2_leaf_reg': 0.00013028549097931553, 'one_hot_max_size': 100, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4406147389\n",
      "bestIteration = 89\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4327069573\n",
      "bestIteration = 199\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4441346609\n",
      "bestIteration = 199\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4439378042\n",
      "bestIteration = 199\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4282226108\n",
      "bestIteration = 199\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:32:39,034]\u001b[0m Trial 13 finished with value: 0.8596106853026626 and parameters: {'iterations': 200, 'learning_rate': 0.015312092326589866, 'random_strength': 1, 'bagging_temperature': 5, 'max_bin': 6, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 3, 'max_depth': 6, 'l2_leaf_reg': 0.20127448967652853, 'one_hot_max_size': 1024, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.450678261\n",
      "bestIteration = 199\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4633250379\n",
      "bestIteration = 89\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4798457975\n",
      "bestIteration = 92\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4970905181\n",
      "bestIteration = 43\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4630943367\n",
      "bestIteration = 90\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:32:44,930]\u001b[0m Trial 14 finished with value: 0.8527818406106465 and parameters: {'iterations': 1500, 'learning_rate': 0.14690216116501453, 'random_strength': 10, 'bagging_temperature': 2, 'max_bin': 10, 'grow_policy': 'Lossguide', 'min_data_in_leaf': 3, 'max_depth': 9, 'l2_leaf_reg': 0.0012700604558864655, 'one_hot_max_size': 5, 'auto_class_weights': 'Balanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4881113768\n",
      "bestIteration = 88\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4144923871\n",
      "bestIteration = 151\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4351198193\n",
      "bestIteration = 135\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4380786963\n",
      "bestIteration = 149\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4220213145\n",
      "bestIteration = 125\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:32:49,995]\u001b[0m Trial 15 finished with value: 0.8609241246295614 and parameters: {'iterations': 500, 'learning_rate': 0.10902072034609422, 'random_strength': 9, 'bagging_temperature': 10, 'max_bin': 4, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 5, 'max_depth': 4, 'l2_leaf_reg': 9.46314667205651e-06, 'one_hot_max_size': 12, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4421279212\n",
      "bestIteration = 138\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4164598089\n",
      "bestIteration = 117\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4316936218\n",
      "bestIteration = 95\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4328478872\n",
      "bestIteration = 129\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4151045199\n",
      "bestIteration = 96\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:32:53,002]\u001b[0m Trial 16 finished with value: 0.8637084217832557 and parameters: {'iterations': 300, 'learning_rate': 0.19373131951584033, 'random_strength': 6, 'bagging_temperature': 4, 'max_bin': 8, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 8, 'max_depth': 3, 'l2_leaf_reg': 0.17933449466684065, 'one_hot_max_size': 500, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4410023887\n",
      "bestIteration = 118\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4198496509\n",
      "bestIteration = 270\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4340202546\n",
      "bestIteration = 293\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4424190968\n",
      "bestIteration = 193\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4177517892\n",
      "bestIteration = 297\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:33:12,467]\u001b[0m Trial 17 finished with value: 0.8615975747025792 and parameters: {'iterations': 1000, 'learning_rate': 0.049633505636177605, 'random_strength': 9, 'bagging_temperature': 7, 'max_bin': 5, 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 2, 'max_depth': 6, 'l2_leaf_reg': 0.007808292782556029, 'one_hot_max_size': 100, 'auto_class_weights': 'SqrtBalanced'}. Best is trial 1 with value: 0.8651912924685078.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4389945698\n",
      "bestIteration = 279\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.4448853147\n",
      "bestIteration = 250\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4641279581\n",
      "bestIteration = 160\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4672899176\n",
      "bestIteration = 217\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4426935548\n",
      "bestIteration = 256\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:33:18,753]\u001b[0m Trial 18 finished with value: 0.8658380772528973 and parameters: {'iterations': 1500, 'learning_rate': 0.10620743554253874, 'random_strength': 7, 'bagging_temperature': 3, 'max_bin': 6, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 2, 'max_depth': 3, 'l2_leaf_reg': 77.18909314164286, 'one_hot_max_size': 500, 'auto_class_weights': 'Balanced'}. Best is trial 18 with value: 0.8658380772528973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4696789675\n",
      "bestIteration = 199\n",
      "\n",
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.445803794\n",
      "bestIteration = 199\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.4617681462\n",
      "bestIteration = 179\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.4674646175\n",
      "bestIteration = 151\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.4445566233\n",
      "bestIteration = 178\n",
      "\n",
      "Training on fold [4/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-25 17:33:24,123]\u001b[0m Trial 19 finished with value: 0.8659247618189543 and parameters: {'iterations': 200, 'learning_rate': 0.11785297050011456, 'random_strength': 5, 'bagging_temperature': 3, 'max_bin': 10, 'grow_policy': 'Depthwise', 'min_data_in_leaf': 2, 'max_depth': 3, 'l2_leaf_reg': 99.11695455168547, 'one_hot_max_size': 500, 'auto_class_weights': 'Balanced'}. Best is trial 19 with value: 0.8659247618189543.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.4695991366\n",
      "bestIteration = 175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "sampler = optuna.samplers.TPESampler(seed=68)  # Make the sampler behave in a deterministic way.\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 20\n",
      "Best trial:\n",
      "  Value: 0.8659247618189543\n",
      "  Params: \n",
      "    iterations=200,\n",
      "    learning_rate=0.11785297050011456,\n",
      "    random_strength=5,\n",
      "    bagging_temperature=3,\n",
      "    max_bin=10,\n",
      "    grow_policy=Depthwise,\n",
      "    min_data_in_leaf=2,\n",
      "    max_depth=3,\n",
      "    l2_leaf_reg=99.11695455168547,\n",
      "    one_hot_max_size=500,\n",
      "    auto_class_weights=Balanced,\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}={},\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = CatBoostClassifier(verbose=False,**trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2723a3c19d0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X_train_processed, y_train.h1n1_vaccine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_h1 = final_model.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7940792951423642"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test.h1n1_vaccine, predictions_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "Bad value for num_feature[non_default_doc_idx=0,feature_idx=21]=\"55 - 64 Years\": Cannot convert 'b'55 - 64 Years'' to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_float_feature\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._FloatOrNan\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._FloatOrNanFromString\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert 'b'55 - 64 Years'' to float",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-154-4f989182bd9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh1n1_vaccine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   4766\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss_function'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4768\u001b[1;33m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[0;32m   4769\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4770\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2071\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2072\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2073\u001b[1;33m         train_params = self._prepare_train_params(\n\u001b[0m\u001b[0;32m   2074\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m             \u001b[0mpairs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         \u001b[0membedding_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_feature_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'embedding_features'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m         train_pool = _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs,\n\u001b[0m\u001b[0;32m   1960\u001b[0m                                        \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1961\u001b[0m                                        baseline, column_description)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_build_train_pool\u001b[1;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[0;32m   1239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m         train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, embedding_features=embedding_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n\u001b[0m\u001b[0;32m   1242\u001b[0m                           group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n\u001b[0;32m   1243\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m    643\u001b[0m                     )\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m                 self._init(data, label, cat_features, text_features, embedding_features, pairs, weight,\n\u001b[0m\u001b[0;32m    646\u001b[0m                            group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[0;32m    647\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_init\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeature_tags\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m             \u001b[0mfeature_tags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_transform_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_tags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1222\u001b[1;33m         self._init_pool(data, label, cat_features, text_features, embedding_features, pairs, weight,\n\u001b[0m\u001b[0;32m   1223\u001b[0m                         group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[0;32m   1224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.create_num_factor_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_float_feature\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=21]=\"55 - 64 Years\": Cannot convert 'b'55 - 64 Years'' to float"
     ]
    }
   ],
   "source": [
    "final_model.fit(X, y.h1n1_vaccine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
